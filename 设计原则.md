今天做出一个产品看似简单，但要做出一个真正有价值的产品，其实远比移动互联网时代更难。

回想移动互联网时代，我们谈论一个好产品，总绕不开「用户体验」。合理、精巧的交互设计，顺滑的用户旅程，往往影响着产品能否快速起量、锁定用户。那时，用户体验很大程度上是产品经理的「审美」问题，是关于洞察与精巧设计的故事。

但在今天，对于 AI Native 产品而言，用户体验已不只是「审美」层面的问题，而是一项技术问题了。当用户与 AI 之间可以通过自然语言联通时，AI Native 产品同时面对着用户需求的「失控」，以及用户体验和用户价值交付的「失控」。

这种双边的「失控感」带来了 AI Native 产品在用户体验上的核心挑战：我们该如何交付更好的用户体验与用户价值？一方面，不可能仅靠一套固定的系统提示词，就完美适配每位用户千差万别的真实需求；另一方面，更不能要求每一个用户都成为提示词大师，懂得如何从大模型这个「Magic Box」中精准、高效地提取能量。结果就是，即便 AI 已成为一种可以无处不在的强大「原力」，但绝大多数人并不能真正驾驭它。

最近关注到硅谷「提示词工程已死」的大辩论，集中地看了一些相关内容，我觉得大神们的探讨也在清晰地指引 AI 产品下一步的进化方向：当前 AI Native 产品的体验瓶颈，本质上是技术问题——不只在模型侧，也在产品工程层面。

所有人期待的 C 端爆款产品迟迟未现，这背后，或许就是用户体验的「卡点」尚未突破。AI Native 产品的用户体验，需要在明确目标下，依托更精巧的产品工程与更强大的模型技术共同进步，才能抵达并突破那个引爆市场的临界点。今天谈「懂人性」和「产品审美」，可能都为时过早。


01 
两条路径，一个被忽略的真相：
「是人不行」
我在今年 AGI Playground 大会的分享中也提到了，AI 产品一定是 Input > Output。

AI 时代，产品的基本构型就是两端分别是 input 和 output，中间的 AI 则是个 Magic Box。大模型的确有 Magic，但问题也在于，它是一个处于失控状态的不确定的概率模型。因此，产品的目标之一就是在不确定性中增加确定性。对于大多不自主研发大模型这个「Magic Box」的团队而言，就要在 input 和 output 这两端上下功夫。对于 input 这一端，我的提法是要做「宽输入」（具体展开可以参见文章：聊过 200 个团队后的暴论：不要拿 AI 造工具，要建设「新关系」）。Karpathy 和 Grove 提出的「上下文工程」和「规范化编程」，也是在 input 上做加强。

我们先来「圈点」一下这两位大神的观点。

Andrej Karpathy的「上下文工程」（Context Engineering），从原材料上做优化，认为 AI 智能体的失败，多半是「上下文的失败」——你没有在对的时机，用对的格式，给它对且充分的信息。他强调要系统化地管理指令、历史、记忆、工具等所有输入，像个「信息架构师」一样，为 AI 精心准备好所有「建材」。

Sean Grove 的「规范化编程」（Spec-writing）直指「用户想要什么」这个根源问题，也看到了大部分人在意图澄清上的欠缺，「人类花费大量精力优化与 AI 的交互，却从未真正说清自己想要什么。」他主张用结构化的规范文档（Spec）来定义目标和价值观，让它成为比代码更重要的「源代码」。

这两条路径都远超了「一次性」的提示词或提示词工程。提示词的困境在于，它把人怼到了一个死角里，它默认「人」是那个清晰、可靠的指令发出方。可现实是，别说普通用户，就算是 CEO，有几个能一上来就把自己的愿景、使命、产品逻辑结构化、无歧义地拆解清楚？又有几个老板能在每次发号施令的时候，把上下文、意图、原则、规范等等都清晰明了地传达？寥寥无几。

Karpathy 和 Grove 的方案，本质上都是在试图「越过」人类的模糊性。Karpathy 想通过优化上下文来「包围」模糊，让 AI 拥有足够信息去自行判断；Grove 则想用一份结构化、可迭代的规范来「穿透」模糊，倒逼人类在行动前完成思考、在行动中持续思考。

02 
AI 的下一站：「人不行」，
所以 AI 必须行
那么，未来向何处前进？

如果解决方案最终还是「靠人想清楚、说透彻」，那它和提示词工程的困境没什么两样，甚至更进一步提高了对人的要求和用好 AI 的门槛。

这才是真正的断点和解法所在：「人不行」，所以 AI 必须行。

由此，我有一个更进一步的判断：解决方案的探索方向，一定不是靠人这一端，而是要靠 AI。

我们不能期待用户都成为上下文管理大师、逻辑大师和沟通天才。未来的 AI 产品一定不是依赖人变得更会提供「上下文」或更会写「规范」，而是 AI 要具备主动性和相应的能力，要能主动「Find Out」合适上下文以及识别、预判用户真实意图。如果 AI 不具备自主处理、定位、匹配、调用合适上下文的能力，将大批量上下文给到 AI 将是个灾难。

AI 还要继续进化。它要像一个真正的伙伴，能从我们杂乱的「生活流」（lifestream）中，从我们碎片化的表达和行为中，去主动地、持续地理解、提炼、调用，甚至预测我们的真实意图。在一份全面、明晰、可持续主动迭代的「规范文档」之外，也需要一个动态的、不断生长的「数据流」。

这正是我说的「宽输入」的终极目标：多模态感知，对生活流的高分辨率捕捉。并且，要能在 input 和 output 之间形成闭环来实现「自进化」。

Karpathy 和 Grove 的工作，在我看来，正是在为 AI 建立这种能力。他们并非在等待一个完美的「人」来喂养数据，而是在 AI 这一端构建一套机制，弥合人这一端的欠缺，让 AI 更好地消化和理解这个不完美的、混沌的真实世界，能与不完美、不明晰的人类更好地协作。

你看，Karpathy 说的要管理上下文，其实很大一部分在于模型要怎么学着自己去 manage context；Grove 说要有规范，其实是要让模型学着如何把模糊的人类价值观，对齐到自己可执行的目标上。

这几位大神都绝对信 AI，不那么信人，所以他们一定会站在 AI 的角度去思考：我下一步该怎么做，才能解决「人不行」的问题？

Karpathy 和 Grove 给出「上下文工程」和「规范编程」肯定也不是终极的解法，但是他们将问题更清晰地摆在了桌面上。这也说明了一点，传统意义上的产品经理们，如今面临的挑战确实变大了。因为在这个时代，必须先懂「模性」，才轮得到发挥「懂人性」的作用；若没有 AI 技术和工程上的「审美」，产品的「审美」也大概率没办法闪耀光辉。